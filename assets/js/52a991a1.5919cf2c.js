"use strict";(self.webpackChunkdocusaurus_temp=self.webpackChunkdocusaurus_temp||[]).push([[9848],{1924:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_44_0-ba8c923246f84192ed980681502b891a.png"},3127:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_20_1-45748cf2b7d96bb2205a4f87b27047c3.png"},3497:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_46_3-957645deed9be60db36ab444b0cb533d.png"},3687:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_19_1-7669772525cb1662bb34a0fd521476c3.png"},4008:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_23_1-5f0d8b8c64d6a3fd3a1a9b1c8ed68b5f.png"},4609:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_40_1-1f8a128290ffdb2d3a92eab3d5015cb1.png"},4851:(e,n,d)=>{d.r(n),d.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>o,frontMatter:()=>i,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"Python/PythonforDataScience/ML_Clust","title":"ML_Clust","description":"\ud83c\udfe0 Home","source":"@site/docs/Python/PythonforDataScience/7_ML_Clust.md","sourceDirName":"Python/PythonforDataScience","slug":"/Python/PythonforDataScience/ML_Clust","permalink":"/docs/Python/PythonforDataScience/ML_Clust","draft":false,"unlisted":false,"editUrl":"https://github.com/csjoshc/csjoshc.github.io/tree/main/docs/Python/PythonforDataScience/7_ML_Clust.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"ML","permalink":"/docs/Python/PythonforDataScience/ML"},"next":{"title":"ML_DT","permalink":"/docs/Python/PythonforDataScience/ML_DT"}}');var s=d(4848),r=d(8453);const i={},l="Clustering - kmeans",c={},h=[{value:"Joining data",id:"joining-data",level:2},{value:"Splitting columns - title and year",id:"splitting-columns---title-and-year",level:2},{value:"Exploring Correlation",id:"exploring-correlation",level:2},{value:"What&#39;s next?",id:"whats-next",level:2},{value:"Binning results",id:"binning-results",level:2},{value:"Exploratory elbow plot",id:"exploratory-elbow-plot",level:2},{value:"Elbow plot - defining the bend mathematically",id:"elbow-plot---defining-the-bend-mathematically",level:2}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"\ud83c\udfe0 Home\n\ud83d\udc0d Python"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'\ntime_start = datetime.datetime.now()\n\nprint(sys.executable)\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = "all"\nInteractiveShell.colors = "Linux"\nInteractiveShell.separate_in = 0\n'})}),"\n",(0,s.jsx)(n.p,{children:"/home/jcmint/anaconda3/envs/learningenv/bin/python"}),"\n",(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"clustering---kmeans",children:"Clustering - kmeans"})}),"\n",(0,s.jsx)(n.p,{children:"The clustering tutorial was based on weather data and classifying them into hot or cold days based on 7-8 features. However, I wanted to try something on my own using the movies rating data. I wanted to 2-D graph movies by the number of raters and the average score, and plot. Then, I would use a third variable (the decade it was released) to color the points, to see if movies released in certain decades were more actively reviewed or had higher. A fourth variable, the average review timestamp, would be used as intensity for a heatmap for the color variable.\nAfter assessing the data, I would then run the data through a cluster algoritm, including generating an elbow curve."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\nfrom itertools import cycle, islice\nimport matplotlib.pyplot as plt\n\nsns.set(style="ticks", context="talk")\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"movies = pd.read_csv('../../../../data/w4pd/movies.csv')\nratings = pd.read_csv('../../../../data/w4pd/ratings.csv')\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"movies.shape, ratings.shape\nmovies.head()\nratings.head()\n"})}),"\n",(0,s.jsx)(n.p,{children:"((27278, 3), (20000263, 4))"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"title"}),(0,s.jsx)(n.th,{children:"genres"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"Toy Story (1995)"}),(0,s.jsx)(n.td,{children:"Adventure"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"Jumanji (1995)"}),(0,s.jsx)(n.td,{children:"Adventure"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"Grumpier Old Men (1995)"}),(0,s.jsx)(n.td,{children:"Comedy"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"Waiting to Exhale (1995)"}),(0,s.jsx)(n.td,{children:"Comedy"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"Father of the Bride Part II (1995)"}),(0,s.jsx)(n.td,{children:"Comedy"})]})]})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"userId"}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"rating"}),(0,s.jsx)(n.th,{children:"timestamp"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3.5"}),(0,s.jsx)(n.td,{children:"1112486027"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"29"}),(0,s.jsx)(n.td,{children:"3.5"}),(0,s.jsx)(n.td,{children:"1112484676"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"3.5"}),(0,s.jsx)(n.td,{children:"1112484819"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"47"}),(0,s.jsx)(n.td,{children:"3.5"}),(0,s.jsx)(n.td,{children:"1112484727"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"50"}),(0,s.jsx)(n.td,{children:"3.5"}),(0,s.jsx)(n.td,{children:"1112484580"})]})]})]}),"\n",(0,s.jsx)(n.h1,{id:"data-prep",children:"Data Prep"}),"\n",(0,s.jsx)(n.h2,{id:"joining-data",children:"Joining data"}),"\n",(0,s.jsx)(n.p,{children:"Here, I join together two tables and calculate aggregate values, so that I condense the information from million of rows into a few tens of thousands."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"movie_ratings = ratings[['movieId', 'rating']].groupby('movieId').mean() \nmovie_counts = ratings[['movieId', 'rating']].groupby('movieId').count() \nmovie_timestamps = pd.to_datetime(ratings[['movieId', 'timestamp']].groupby('movieId').mean()['timestamp'], unit = 's').dt.date\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'print("Timestamp range is ", movie_timestamps.min(), " to ", movie_timestamps.max())\n'})}),"\n",(0,s.jsx)(n.p,{children:"Timestamp range is  1997-03-02  to  2015-03-30"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"merged_1 = movie_ratings.merge(movie_counts, on = 'movieId', how='inner').merge(movie_timestamps, on = 'movieId', how='inner')\nmerged_1 = merged_1.merge(movies[['movieId', 'title']], on = 'movieId', how='inner')\nmerged_1.head()\n"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"rating_x"}),(0,s.jsx)(n.th,{children:"rating_y"}),(0,s.jsx)(n.th,{children:"timestamp"}),(0,s.jsx)(n.th,{children:"title"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"3.921240"}),(0,s.jsx)(n.td,{children:"49695"}),(0,s.jsx)(n.td,{children:"2003-05-11"}),(0,s.jsx)(n.td,{children:"Toy Story (1995)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3.211977"}),(0,s.jsx)(n.td,{children:"22243"}),(0,s.jsx)(n.td,{children:"2002-11-18"}),(0,s.jsx)(n.td,{children:"Jumanji (1995)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"3.151040"}),(0,s.jsx)(n.td,{children:"12735"}),(0,s.jsx)(n.td,{children:"2000-05-30"}),(0,s.jsx)(n.td,{children:"Grumpier Old Men (1995)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"2.861393"}),(0,s.jsx)(n.td,{children:"2756"}),(0,s.jsx)(n.td,{children:"1999-04-15"}),(0,s.jsx)(n.td,{children:"Waiting to Exhale (1995)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"3.064592"}),(0,s.jsx)(n.td,{children:"12161"}),(0,s.jsx)(n.td,{children:"2000-06-26"}),(0,s.jsx)(n.td,{children:"Father of the Bride Part II (1995)"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"splitting-columns---title-and-year",children:"Splitting columns - title and year"}),"\n",(0,s.jsx)(n.p,{children:"Next, extract the year from the title and bin into a decade"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"Title = merged_1['title'].str.extract('(.+?) \\(')\nYear  = merged_1['title'].str.extract('(\\d\\d\\d\\d)')\nTitle = Title.rename(columns = {Title.columns[0]: \"Name\"})\nYear = Year.rename(columns = {Year.columns[0]: \"Year\"})\nmerged_1 = pd.concat([merged_1, Title, Year], axis = 1, join = \"inner\")\nmerged_1.head()\n"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"rating_x"}),(0,s.jsx)(n.th,{children:"rating_y"}),(0,s.jsx)(n.th,{children:"timestamp"}),(0,s.jsx)(n.th,{children:"title"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"3.921240"}),(0,s.jsx)(n.td,{children:"49695"}),(0,s.jsx)(n.td,{children:"2003-05-11"}),(0,s.jsx)(n.td,{children:"Toy Story (1995)"}),(0,s.jsx)(n.td,{children:"Toy Story"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3.211977"}),(0,s.jsx)(n.td,{children:"22243"}),(0,s.jsx)(n.td,{children:"2002-11-18"}),(0,s.jsx)(n.td,{children:"Jumanji (1995)"}),(0,s.jsx)(n.td,{children:"Jumanji"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"3.151040"}),(0,s.jsx)(n.td,{children:"12735"}),(0,s.jsx)(n.td,{children:"2000-05-30"}),(0,s.jsx)(n.td,{children:"Grumpier Old Men (1995)"}),(0,s.jsx)(n.td,{children:"Grumpier Old Men"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"2.861393"}),(0,s.jsx)(n.td,{children:"2756"}),(0,s.jsx)(n.td,{children:"1999-04-15"}),(0,s.jsx)(n.td,{children:"Waiting to Exhale (1995)"}),(0,s.jsx)(n.td,{children:"Waiting to Exhale"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"3.064592"}),(0,s.jsx)(n.td,{children:"12161"}),(0,s.jsx)(n.td,{children:"2000-06-26"}),(0,s.jsx)(n.td,{children:"Father of the Bride Part II (1995)"}),(0,s.jsx)(n.td,{children:"Father of the Bride Part II"}),(0,s.jsx)(n.td,{children:"1995"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"Finally, drop the title column since it's been split"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'del merged_1[\'title\']\nmerged_1 = merged_1.rename(columns={merged_1.columns[1]: "Score", merged_1.columns[2] : "Ratings", merged_1.columns[3]:"Date"})\nmerged_1.head()\n'})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"3.921240"}),(0,s.jsx)(n.td,{children:"49695"}),(0,s.jsx)(n.td,{children:"2003-05-11"}),(0,s.jsx)(n.td,{children:"Toy Story"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3.211977"}),(0,s.jsx)(n.td,{children:"22243"}),(0,s.jsx)(n.td,{children:"2002-11-18"}),(0,s.jsx)(n.td,{children:"Jumanji"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"3.151040"}),(0,s.jsx)(n.td,{children:"12735"}),(0,s.jsx)(n.td,{children:"2000-05-30"}),(0,s.jsx)(n.td,{children:"Grumpier Old Men"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"2.861393"}),(0,s.jsx)(n.td,{children:"2756"}),(0,s.jsx)(n.td,{children:"1999-04-15"}),(0,s.jsx)(n.td,{children:"Waiting to Exhale"}),(0,s.jsx)(n.td,{children:"1995"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"3.064592"}),(0,s.jsx)(n.td,{children:"12161"}),(0,s.jsx)(n.td,{children:"2000-06-26"}),(0,s.jsx)(n.td,{children:"Father of the Bride Part II"}),(0,s.jsx)(n.td,{children:"1995"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"I need to actually hold onto the POSIX average rating timestamps so that I can convert them to numbers for analysis."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"scaled_1 = merged_1.copy()\ndel scaled_1['Name']\ndel scaled_1['Date']\nscaled_1 = scaled_1.merge(ratings[['movieId', 'timestamp']].groupby('movieId').mean().astype(int), on = 'movieId', how='inner') \ndel scaled_1['movieId']\nscaled_1 = scaled_1.rename(columns={scaled_1.columns[3]: \"Date\"})\nscaled_1.head()\n"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Year"}),(0,s.jsx)(n.th,{children:"Date"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"3.921240"}),(0,s.jsx)(n.td,{children:"49695"}),(0,s.jsx)(n.td,{children:"1995"}),(0,s.jsx)(n.td,{children:"1052654098"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"3.211977"}),(0,s.jsx)(n.td,{children:"22243"}),(0,s.jsx)(n.td,{children:"1995"}),(0,s.jsx)(n.td,{children:"1037616295"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3.151040"}),(0,s.jsx)(n.td,{children:"12735"}),(0,s.jsx)(n.td,{children:"1995"}),(0,s.jsx)(n.td,{children:"959648019"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"2.861393"}),(0,s.jsx)(n.td,{children:"2756"}),(0,s.jsx)(n.td,{children:"1995"}),(0,s.jsx)(n.td,{children:"924214411"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"3.064592"}),(0,s.jsx)(n.td,{children:"12161"}),(0,s.jsx)(n.td,{children:"1995"}),(0,s.jsx)(n.td,{children:"962016085"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"%%capture\nscaled_1['Year'] = pd.to_numeric(scaled_1['Year'])\nvar_corr = scaled_1.corr()\nnormalized = StandardScaler().fit_transform(scaled_1)\n"})}),"\n",(0,s.jsx)(n.h1,{id:"visualization",children:"Visualization"}),"\n",(0,s.jsx)(n.h2,{id:"exploring-correlation",children:"Exploring Correlation"}),"\n",(0,s.jsx)(n.p,{children:"Finally, we can graph our data, starting with a heatmap for correlation between numerical variables (this is why I needed to hold onto the rating timestamp in POSIX format, since I wasn't able top pass a human readable format directly into the method."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"sns.heatmap(var_corr)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"png",src:d(3687).A+"",width:"447",height:"268"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"fig, axis = plt.subplots()\nfig.set_size_inches(11.7, 4)\naxis.set_title('Ratings vs Rating Date',fontsize=26)\naxis.set_xlabel('Average Date of Ratings',fontsize=18)\naxis.set_ylabel('Number of Ratings',fontsize=18)\nplt.plot_date(x='Date', y = 'Ratings', data = merged_1)\nplt.show();\nfig, axis = plt.subplots()\nfig.set_size_inches(6, 10)\naxis.set_title('Score vs Ratings',fontsize=26)\naxis.set_xlabel('Number of Ratings',fontsize=18)\naxis.set_ylabel('Average Score',fontsize=18)\nplt.scatter(x='Ratings', y = 'Score', marker = '.', s=4, data = merged_1)\nplt.show();\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"png",src:d(7342).A+"",width:"770",height:"307"}),"\n",(0,s.jsx)(n.img,{alt:"png",src:d(3127).A+"",width:"403",height:"633"})]}),"\n",(0,s.jsx)(n.h2,{id:"whats-next",children:"What's next?"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Bin 'Year' column into decades so I can color by the different buckets. Use this to compare to the clusters generated by kmeans clustering (color by either classification and compare side by side)"}),"\n",(0,s.jsxs)(n.li,{children:["Since I'm already familiar with ggplot, I would want to try to use ",(0,s.jsx)(n.a,{href:"https://github.com/has2k1/plotnine",children:"python ggplot"})," to color and facet by categorical variable and see if I can do something with it"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.code,{children:"conda install -c conda-forge plotnine"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"merged_1['Year'] = pd.to_numeric(merged_1['Year'])\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from plotnine import ggplot, geom_point, aes, stat_smooth, geom_histogram\nggplot() + geom_histogram(aes('Year'), data = merged_1)\n"})}),"\n",(0,s.jsxs)(n.p,{children:["/home/jcmint/anaconda3/envs/learningenv/lib/python3.7/site-packages/plotnine/stats/stat_bin.py:93: UserWarning: 'stat_bin()' using 'bins = 3865'. Pick better value with 'binwidth'.\nwarn(msg.format(params['bins']))\n/home/jcmint/anaconda3/envs/learningenv/lib/python3.7/site-packages/plotnine/layer.py:360: UserWarning: stat_bin : Removed 19 rows containing non-finite values.\ndata = self.stat.compute_layer(data, params, layout)\n",(0,s.jsx)(n.img,{alt:"png",src:d(4008).A+"",width:"887",height:"587"})]}),"\n",(0,s.jsx)(n.p,{children:"What is going on with the Year column of merged_1? Very odd, so I look at min and max."}),"\n",(0,s.jsx)(n.h1,{id:"further-data-cleaning",children:"Further Data Cleaning"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"merged_1['Year'].min(), merged_1['Year'].max()\nmovies[movies['title'].str.contains('1000')]\nmovies[movies['title'].str.contains('9012')]\nmerged_1[merged_1['Year']==1000]\nmerged_1[merged_1['Year']==9012]\n"})}),"\n",(0,s.jsx)(n.p,{children:"(1000.0, 9012.0)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"title"}),(0,s.jsx)(n.th,{children:"genres"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"6191"}),(0,s.jsx)(n.td,{children:"6290"}),(0,s.jsx)(n.td,{children:"House of 1000 Corpses (2003)"}),(0,s.jsx)(n.td,{children:"Horror"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"7695"}),(0,s.jsx)(n.td,{children:"8198"}),(0,s.jsx)(n.td,{children:"1000 Eyes of Dr. Mabuse, The (Die 1000 Augen d..."}),(0,s.jsx)(n.td,{children:"Crime"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"22287"}),(0,s.jsx)(n.td,{children:"107155"}),(0,s.jsx)(n.td,{children:"Captive Women (1000 Years from Now) (3000 A.D...."}),(0,s.jsx)(n.td,{children:"Sci-Fi"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"26429"}),(0,s.jsx)(n.td,{children:"126999"}),(0,s.jsx)(n.td,{children:"1000 Journals (2007)"}),(0,s.jsx)(n.td,{children:"(no genres listed)"})]})]})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"title"}),(0,s.jsx)(n.th,{children:"genres"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"18578"}),(0,s.jsx)(n.td,{children:"92477"}),(0,s.jsx)(n.td,{children:"Yes: 9012 Live (1985)"}),(0,s.jsx)(n.td,{children:"Documentary"})]})})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"6191"}),(0,s.jsx)(n.td,{children:"6290"}),(0,s.jsx)(n.td,{children:"2.855172"}),(0,s.jsx)(n.td,{children:"870"}),(0,s.jsx)(n.td,{children:"2007-08-23"}),(0,s.jsx)(n.td,{children:"House of 1000 Corpses"}),(0,s.jsx)(n.td,{children:"1000.0"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"7695"}),(0,s.jsx)(n.td,{children:"8198"}),(0,s.jsx)(n.td,{children:"3.398438"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"2008-06-21"}),(0,s.jsx)(n.td,{children:"1000 Eyes of Dr. Mabuse, The"}),(0,s.jsx)(n.td,{children:"1000.0"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"22185"}),(0,s.jsx)(n.td,{children:"107155"}),(0,s.jsx)(n.td,{children:"0.500000"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2014-04-13"}),(0,s.jsx)(n.td,{children:"Captive Women"}),(0,s.jsx)(n.td,{children:"1000.0"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"25962"}),(0,s.jsx)(n.td,{children:"126999"}),(0,s.jsx)(n.td,{children:"2.000000"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2015-01-30"}),(0,s.jsx)(n.td,{children:"1000 Journals"}),(0,s.jsx)(n.td,{children:"1000.0"})]})]})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"18533"}),(0,s.jsx)(n.td,{children:"92477"}),(0,s.jsx)(n.td,{children:"1.5"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2012-01-22"}),(0,s.jsx)(n.td,{children:"Yes: 9012 Live"}),(0,s.jsx)(n.td,{children:"9012.0"})]})})]}),"\n",(0,s.jsx)(n.p,{children:"I guess I could fiddle with the regex more but I'd rather just manually assign these and move on. I need to find the release years for the movie titles that were cut off first, and then find the correct index by the movieId in the merged dataframe. It seems like movie with Id 6290 wasn't actually misassigned since its year doesn't equal 1000 in the merged table."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"print(\"Movie row number 7695, movieId 8198:\", movies.iloc[7695, 1])\nprint(\"Movie row number 22287, movieId 107155:\", movies.iloc[22287, 1])\n# fixing the year = 1000 entry\nmerged_1[merged_1['movieId'] == 8198]\nmerged_1.iloc[7695, 5] = 1960\nmerged_1[merged_1['movieId'] == 107155]\nmerged_1.iloc[22185, 5] = 1960\nmerged_1[merged_1['movieId'] == 126999]\nmerged_1.iloc[25962, 5] = 2007\n# Fixing the year = 9012 entry\nmerged_1[merged_1['movieId'] == 92477]\nmerged_1.iloc[18533, 5] = 1985\n"})}),"\n",(0,s.jsx)(n.p,{children:"Movie row number 7695, movieId 8198: 1000 Eyes of Dr. Mabuse, The (Die 1000 Augen des Dr. Mabuse) (1960)\nMovie row number 22287, movieId 107155: Captive Women (1000 Years from Now) (3000 A.D.) (1952)"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"7695"}),(0,s.jsx)(n.td,{children:"8198"}),(0,s.jsx)(n.td,{children:"3.398438"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"2008-06-21"}),(0,s.jsx)(n.td,{children:"1000 Eyes of Dr. Mabuse, The"}),(0,s.jsx)(n.td,{children:"1000.0"})]})})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"22185"}),(0,s.jsx)(n.td,{children:"107155"}),(0,s.jsx)(n.td,{children:"0.5"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2014-04-13"}),(0,s.jsx)(n.td,{children:"Captive Women"}),(0,s.jsx)(n.td,{children:"1000.0"})]})})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"25962"}),(0,s.jsx)(n.td,{children:"126999"}),(0,s.jsx)(n.td,{children:"2.0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2015-01-30"}),(0,s.jsx)(n.td,{children:"1000 Journals"}),(0,s.jsx)(n.td,{children:"1000.0"})]})})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"movieId"}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"Name"}),(0,s.jsx)(n.th,{children:"Year"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"18533"}),(0,s.jsx)(n.td,{children:"92477"}),(0,s.jsx)(n.td,{children:"1.5"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2012-01-22"}),(0,s.jsx)(n.td,{children:"Yes: 9012 Live"}),(0,s.jsx)(n.td,{children:"9012.0"})]})})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"merged_1['Year'].min(), merged_1['Year'].max()\n"})}),"\n",(0,s.jsx)(n.p,{children:"(1000.0, 9000.0)\nSo at this point, I want to just find all the values from before 1900 and after 2018. Based on this the regex matching needs a bit of work to accurately grab values. Since I did want to focus more on machine learning rather than string manipulation for now I'll just drop these rows, since they only represent a tiny, tiny subset of data (I have 27 thousand rows)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"cond_1 = merged_1['Year'] > 2016\ncond_2 = merged_1['Year']  2016\ncond_2 = merged_1['Year'] \n\n![png](7_ML_Clust_files/7_ML_Clust_31_5.png)\n# Returning to visualization\nCompare the heatmaps before and after removing the outlier years, and get a new scaled version \n```python\nscaled_1 = merged_1.copy()\ndel scaled_1['Name']\ndel scaled_1['Date']\nscaled_1 = scaled_1.merge(ratings[['movieId', 'timestamp']].groupby('movieId').mean().astype(int), on = 'movieId', how='inner') \ndel scaled_1['movieId']\nscaled_1 = scaled_1.rename(columns={scaled_1.columns[3]: \"Date\"})\nscaled_1['Year'] = pd.to_numeric(scaled_1['Year'])\nvar_corr = scaled_1.corr()\nnormalized = StandardScaler().fit_transform(scaled_1)\nsns.heatmap(var_corr)\n"})}),"\n",(0,s.jsx)(n.p,{children:"/home/jcmint/anaconda3/envs/learningenv/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\nreturn self.partial_fit(X, y)\n/home/jcmint/anaconda3/envs/learningenv/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\nreturn self.fit(X, **fit_params).transform(X)"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"png",src:d(5244).A+"",width:"447",height:"268"}),"\nSo it seems like the outliers and misidentified values had some influence on the Year correlation with other variables."]}),"\n",(0,s.jsx)(n.h1,{id:"data-manipulations---binning",children:"Data Manipulations - Binning"}),"\n",(0,s.jsx)(n.p,{children:"Here, I want to bin the release year into decade buckets so that I can use that as a factor level to color the plots."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"bins =  [\"{0}s\".format(decades) for decades in range(1900, 2020, 10)]\nnum_bins = len(bins)\nscaled_1['decade'] = pd.cut(x=scaled_1['Year'], bins=num_bins, labels=bins)\nscaled_1.head()\nscaled_1.tail()\n"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Year"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"decade"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"3.921240"}),(0,s.jsx)(n.td,{children:"49695"}),(0,s.jsx)(n.td,{children:"1995.0"}),(0,s.jsx)(n.td,{children:"1052654098"}),(0,s.jsx)(n.td,{children:"1990s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"3.211977"}),(0,s.jsx)(n.td,{children:"22243"}),(0,s.jsx)(n.td,{children:"1995.0"}),(0,s.jsx)(n.td,{children:"1037616295"}),(0,s.jsx)(n.td,{children:"1990s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"3.151040"}),(0,s.jsx)(n.td,{children:"12735"}),(0,s.jsx)(n.td,{children:"1995.0"}),(0,s.jsx)(n.td,{children:"959648019"}),(0,s.jsx)(n.td,{children:"1990s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"2.861393"}),(0,s.jsx)(n.td,{children:"2756"}),(0,s.jsx)(n.td,{children:"1995.0"}),(0,s.jsx)(n.td,{children:"924214411"}),(0,s.jsx)(n.td,{children:"1990s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"3.064592"}),(0,s.jsx)(n.td,{children:"12161"}),(0,s.jsx)(n.td,{children:"1995.0"}),(0,s.jsx)(n.td,{children:"962016085"}),(0,s.jsx)(n.td,{children:"1990s"})]})]})]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"Score"}),(0,s.jsx)(n.th,{children:"Ratings"}),(0,s.jsx)(n.th,{children:"Year"}),(0,s.jsx)(n.th,{children:"Date"}),(0,s.jsx)(n.th,{children:"decade"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"26684"}),(0,s.jsx)(n.td,{children:"4.0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2007.0"}),(0,s.jsx)(n.td,{children:"1427743979"}),(0,s.jsx)(n.td,{children:"2010s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"26685"}),(0,s.jsx)(n.td,{children:"4.0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2002.0"}),(0,s.jsx)(n.td,{children:"1427744888"}),(0,s.jsx)(n.td,{children:"2000s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"26686"}),(0,s.jsx)(n.td,{children:"2.5"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2014.0"}),(0,s.jsx)(n.td,{children:"1427745392"}),(0,s.jsx)(n.td,{children:"2010s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"26687"}),(0,s.jsx)(n.td,{children:"3.0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2001.0"}),(0,s.jsx)(n.td,{children:"1427745466"}),(0,s.jsx)(n.td,{children:"2000s"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"26688"}),(0,s.jsx)(n.td,{children:"4.0"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2014.0"}),(0,s.jsx)(n.td,{children:"1427747966"}),(0,s.jsx)(n.td,{children:"2010s"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"binning-results",children:"Binning results"}),"\n",(0,s.jsx)(n.p,{children:"Plot all the data, divided by decade of release."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Drop na year values\nscaled_1.dropna(inplace = True)\nscaled_1['log_Ratings'] = np.log(scaled_1['Ratings'])\n\nfrom plotnine import facet_wrap\nops.figure_size = (10.4, 6.8)\nggplot(scaled_1, aes('log_Ratings', 'Score', color = 'Year')) + geom_point() + stat_smooth() + facet_wrap('~decade')\n"})}),"\n",(0,s.jsxs)(n.p,{children:["/home/jcmint/anaconda3/envs/learningenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\nreturn ptp(axis=axis, out=out, **kwargs)\n",(0,s.jsx)(n.img,{alt:"png",src:d(6531).A+"",width:"972",height:"604"})]}),"\n",(0,s.jsx)(n.h1,{id:"modeling",children:"Modeling"}),"\n",(0,s.jsx)(n.h2,{id:"exploratory-elbow-plot",children:"Exploratory elbow plot"}),"\n",(0,s.jsx)(n.p,{children:"I generate an elbow plot to see how many clusters might be a good value."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"%%capture\nX = StandardScaler().fit_transform(scaled_1[['Score', 'Ratings', 'Date']])\nerror = []\nfor k in range(2, 20):\n    kmeans_model = KMeans(n_clusters = k);\n    kmeans_model.fit(X);\n    error.append(kmeans_model.inertia_);\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"error = pd.Series(error)\nelbow = pd.DataFrame({'Clusters': list(range(2,20)), 'Error' : error} ) \n\nfrom plotnine import geom_line \nfrom plotnine import scale_x_continuous\nggplot(elbow, aes(x = 'Clusters', y = 'Error')) + geom_line() + scale_x_continuous(breaks = list(range(2,20)))\n"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"Clusters"}),(0,s.jsx)(n.th,{children:"Error"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"56811.269952"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"40924.920341"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"27773.559122"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"23374.464711"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"6"}),(0,s.jsx)(n.td,{children:"19266.801939"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"16360.115736"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"6"}),(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:"14559.723656"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"9"}),(0,s.jsx)(n.td,{children:"13013.149628"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"11561.152691"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"9"}),(0,s.jsx)(n.td,{children:"11"}),(0,s.jsx)(n.td,{children:"10591.417401"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"12"}),(0,s.jsx)(n.td,{children:"9788.753401"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"11"}),(0,s.jsx)(n.td,{children:"13"}),(0,s.jsx)(n.td,{children:"8926.882872"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"12"}),(0,s.jsx)(n.td,{children:"14"}),(0,s.jsx)(n.td,{children:"8267.855712"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"13"}),(0,s.jsx)(n.td,{children:"15"}),(0,s.jsx)(n.td,{children:"7703.456423"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"14"}),(0,s.jsx)(n.td,{children:"16"}),(0,s.jsx)(n.td,{children:"7303.171993"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"15"}),(0,s.jsx)(n.td,{children:"17"}),(0,s.jsx)(n.td,{children:"6815.445542"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"16"}),(0,s.jsx)(n.td,{children:"18"}),(0,s.jsx)(n.td,{children:"6496.663156"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"17"}),(0,s.jsx)(n.td,{children:"19"}),(0,s.jsx)(n.td,{children:"6190.330783"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"png",src:d(4609).A+"",width:"895",height:"587"})}),"\n",(0,s.jsx)(n.h2,{id:"elbow-plot---defining-the-bend-mathematically",children:"Elbow plot - defining the bend mathematically"}),"\n",(0,s.jsx)(n.p,{children:"In most cases you would just eyeball the curve to see where the dropoff starts to plateau. But since we are using code and there are builtin functions we can easily grab the max of the second derivative as the point where the elbow plot is plateauing most quickly"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"np.diff(elbow['Error'])\nnp.diff(np.diff(elbow['Error']))\nnp.diff(np.diff(elbow['Error'])).max()\n"})}),"\n",(0,s.jsx)(n.p,{children:"array([-15886.34961051, -13151.36121902,  -4399.09441152,  -4107.66277137,\n-2906.68620346,  -1800.3920797 ,  -1546.5740278 ,  -1451.99693761,\n-969.73528993,   -802.66399959,   -861.87052968,   -659.02715945,\n-564.39928912,   -400.28443027,   -487.72645071,   -318.78238598,\n-306.33237349])\narray([2734.98839149, 8752.2668075 ,  291.43164015, 1200.97656791,\n1106.29412376,  253.8180519 ,   94.57709019,  482.26164768,\n167.07129033,  -59.20653009,  202.84337023,   94.62787033,\n164.11485886,  -87.44202044,  168.94406473,   12.45001249])\n8752.266807496679\nFor added confirmation we can plot the first (blue line) and second (red line) derivatives. Indeed, the max of the 2nd derivative is at k = 5."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"diff_1 = [0]\nelbow['First Derivative'] = np.append(np.array([0]), np.diff(elbow['Error']))\nelbow['Second Derivative'] = np.append(np.array([0, 0]), np.diff(np.diff(elbow['Error'])))\nelbow_d = ggplot(elbow, aes(x = 'Clusters', y = 'Error')) + geom_line() + scale_x_continuous(breaks = list(range(2,20))) \nelbow_d + geom_line(aes(x = 'Clusters', y = 'First Derivative'), color = 'blue') + geom_line(aes(x = 'Clusters', y = 'Second Derivative'), color = 'red')\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"png",src:d(1924).A+"",width:"894",height:"588"})}),"\n",(0,s.jsx)(n.h1,{id:"final-cluster-and-visualization",children:"Final cluster and visualization"}),"\n",(0,s.jsx)(n.p,{children:"From this plot we can see that the bend of the elbow plot is mathematically at k = 5 clusters. We can finally move on to the last part, return to using the KMeans model to generate label assignments, and color our data by the different clusters."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"kmeans_model = KMeans(n_clusters = 5);\nkmeans_model.fit(X);\nscaled_1['Cluster'] = kmeans_model.fit_predict(X)\nops.figure_size = (10.4, 6.8)\nggplot(scaled_1, aes('log_Ratings', 'Score', color = 'Cluster')) + geom_point() + facet_wrap('~decade')\nggplot(scaled_1, aes('log_Ratings', 'Year',  color = 'Cluster')) + geom_point() + facet_wrap('~decade')\n"})}),"\n",(0,s.jsxs)(n.p,{children:["KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\nn_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\nrandom_state=None, tol=0.0001, verbose=0)\n",(0,s.jsx)(n.img,{alt:"png",src:d(4891).A+"",width:"960",height:"604"})]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"png",src:d(3497).A+"",width:"983",height:"604"})}),"\n",(0,s.jsx)(n.p,{children:"Since I've faceted the graphs by decade of the movie release year, these plots are slices of a 3d plot. If we imagine that the Ratings and Score are the x and y dimensions when looking straight down, then the Year is the vertical dimensions. Here, I also I give a side view of the decade slices on the Ratings side. Finally, how long did this entire file take to run?"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"time_stop = datetime.datetime.now()\ntime_stop - time_start\n"})}),"\n",(0,s.jsx)(n.p,{children:"datetime.timedelta(seconds=46, microseconds=211675)"})]})}function o(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},4891:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_46_1-12d72fddda53343632e1522436db9f0a.png"},5244:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_33_2-6a49f906bb3e1edfa390abb752d6567e.png"},6531:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_37_1-83dd6ab4d455d61bd0c78e8d1cc50fb0.png"},7342:(e,n,d)=>{d.d(n,{A:()=>t});const t=d.p+"assets/images/7_ML_Clust_20_0-16232a72b0dd442e1aa6fecdcd4dcba6.png"},8453:(e,n,d)=>{d.d(n,{R:()=>i,x:()=>l});var t=d(6540);const s={},r=t.createContext(s);function i(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);